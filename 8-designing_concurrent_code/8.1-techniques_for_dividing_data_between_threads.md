# 8.1 Techniques for dividing data between threads

We need to decide **how many** threads we need and **what tasks** they should be doing, let's start with data.

## 8.1.1 Dividing data between threads before processing begins

The easiest algorithm is split data with `std::for_each` to perform an operation on each element. In order to parallelize we can assign first `N` elements to a thread and so on. No communication with other threads until processing is finished, like *Message Processing Interface* (**MPI**), **OpenMP**, then after parallel processing results are combined in a *reduction* step. Important to identify the reduction step, usually it can be parallelized as well. This technique cannot work if we need to split data during processing, like recursive quicksort.

## 8.1.2 Dividing data recursively

Quicksort is composed by two steps: partition data and recursively sort those partitions. The recursive calls are independent because processing is performed on separate sets of elements. We implemented this using `std::async` to spawn asynchronous tasks for the lower part, this is important to not spawn too many threads, we can also use `std::thread::hardware_concurrency()` for this purpose, and push the data to be processed in a thread-safe stack.

```c++ 
template<typename T>
struct sorter {
    
    struct chunk_to_sort {
        std::list<T> data;
        std::promise<std::list<T> > promise;
    };
    
    // stack of unsorted chunks
    thread_safe_stack<chunk_to_sort> chunks;
    std::vector<std::thread> threads;
    unsigned const max_thread_count;
    std::atomic<bool> end_of_data;
    
    sorter() : 
        max_thread_count(std::thread::hardware_concurrency()-1),
        end_of_data(false)
    {}

    ~sorter() {
        // signal threads that no more work will be needed
        end_of_data = true;
        for (auto const &th : threads) {
            // all the implementation relies on this destructor to 
            // tidy up all the threads 
            if (th.joinable()) th.join();
        }
    }

    void try_sort_chunk() {
        boost::shared_ptr<chunk_to_sort> chunk = chunks.pop();
        if (chunk) sort_chunk(chunk);
    }

    void sort_chunk(boost::shared_ptr<chunk_to_sort> const& chunk) {
        chunk->promise.set_value(do_sort(chunk->data));
    }

    void sort_thread() {
        // the threads sit in a loop trying to sort chunks
        while (!end_of_data) {
            try_sort_chunk();
            // give possibility to other threads to push more work on the stack
            std::this_thread::yield();
        }
    }

    std::list<T> do_sort(std::list<T>& chunk_data) {
        if (chunk_data.empty()) return chunk_data;
        std::list<T> result;
        result.splice(result.begin(), chunk_data, chunk_data.begin());
        T const& partition_val = *result.begin();
        
        // usual partitioning of data
        typename std::list<T>::iterator divide_point = 
            std::partition(chunk_data.begin(), chunk_data.end(), 
            [&](T const& val){return val < partition_val;});
        
        chunk_to_sort new_lower_chunk;
        
        new_lower_chunk.data.splice(new_lower_chunk.data.end(),
            chunk_data, chunk_data.begin(), divide_point);
        
        std::future<std::list<T> > new_lower =
            new_lower_chunk.promise.get_future();

        // instead of spawning a nwe thread, push the chunk
        // inside the stack
        chunks.push(std::move(new_lower_chunk));

        // spawn a thread if we can
        if (threads.size() < max_thread_count)
            threads.push_back(std::thread(&sorter<T>::sort_thread, this));
        
        std::list<T> new_higher(do_sort(chunk_data));
        result.splice(result.end(), new_higher);
        
        // lower chunk might still be handled by another thread, 
        // so we need to wait
        while (new_lower.wait_for(
            std::chrono::seconds(0)) != std::future_status::ready) {
            // while we are waiting we can process another chunk of data
            // from the stack
            try_sort_chunk();
        }

        // merge sub-lists
        result.splice(result.begin(), new_lower.get());
        
        return result;
    }
};

template<typename T>
std::list<T> parallel_quick_sort(std::list<T> input) {
    if (input.empty()) {
        return input;
    }
    // delegate sorting to the sorter class
    sorter<T> s;
    // when all data has been sorted do_sort returns, even if the worker
    // threads are still running, so we can return and destroy sorter obj
    return s.do_sort(input);
}
```
With this approach we resolve the problem of unbounded threads, but we have another problem: managing all this threads adds a notable complexity to the code, moreover contention on the stack can cause a reduction of performances.

If the data is dynamically generated or is coming from external input, this approach doesn't work, in this case dividing work by task type rather then dividing based on data.

## 8.1.3 Dividing work by task type
Dividing works on threads dividing data into chunks relies on the assumption that each thread makes the same processing of its chunk of data. We can think about dividing work by creating specialized threads based on the task they should do, for a good design each piece of code should have a single responsibility.